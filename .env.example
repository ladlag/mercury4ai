# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_KEY=your-secure-api-key-change-this

# Database Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=mercury4ai
POSTGRES_USER=mercury4ai
POSTGRES_PASSWORD=mercury4ai_password

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# MinIO Configuration
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=mercury4ai
MINIO_SECURE=false

# Worker Configuration
WORKER_CONCURRENCY=2

# Crawl Configuration
FALLBACK_DOWNLOAD_ENABLED=true
FALLBACK_DOWNLOAD_MAX_SIZE_MB=10

# LLM Configuration (Optional defaults)
# These defaults are used when tasks don't specify their own LLM configuration

# Recommended: Using DeepSeek (国产大模型 - Cost-effective and high-quality)
DEFAULT_LLM_PROVIDER=openai
DEFAULT_LLM_MODEL=deepseek-chat
DEFAULT_LLM_API_KEY=
DEFAULT_LLM_BASE_URL=https://api.deepseek.com
DEFAULT_LLM_TEMPERATURE=0.1
DEFAULT_LLM_MAX_TOKENS=

# Default prompt template for LLM extraction (optional)
# Can be inline text or file reference like @prompt_templates/detail_page_extract_full.txt
# If not set, tasks must provide their own prompt_template
DEFAULT_PROMPT_TEMPLATE=

# Alternative 1: Using OpenAI
# DEFAULT_LLM_PROVIDER=openai
# DEFAULT_LLM_MODEL=gpt-4
# DEFAULT_LLM_API_KEY=your-openai-api-key
# DEFAULT_LLM_BASE_URL=
# DEFAULT_LLM_TEMPERATURE=0.1
# DEFAULT_LLM_MAX_TOKENS=4000

# Alternative 2: Using Qwen/Tongyi Qianwen (通义千问)
# DEFAULT_LLM_PROVIDER=openai
# DEFAULT_LLM_MODEL=qwen-turbo
# DEFAULT_LLM_API_KEY=your-dashscope-api-key
# DEFAULT_LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# DEFAULT_LLM_TEMPERATURE=0.1
# DEFAULT_LLM_MAX_TOKENS=4000

# Alternative 3: Using Wenxin Yiyan (文心一言)
# DEFAULT_LLM_PROVIDER=openai
# DEFAULT_LLM_MODEL=ernie-bot-turbo
# DEFAULT_LLM_API_KEY=your-baidu-api-key
# DEFAULT_LLM_BASE_URL=https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop
# DEFAULT_LLM_TEMPERATURE=0.1
# DEFAULT_LLM_MAX_TOKENS=4000
